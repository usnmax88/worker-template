# Use the CUDA 12.1 wheels for PyTorch
--extra-index-url https://download.pytorch.org/whl/cu121

runpod>=1.6,<2.0

# PyTorch trio (keep them in the same family)
torch==2.4.0
torchvision==0.19.0
torchaudio==2.4.0

# Essentials
numpy>=1.26,<3
pillow>=10,<11
requests>=2.31,<3
tqdm>=4.66,<5

# Audio processing libraries required by OmniAvatar
librosa>=0.10.0
soundfile>=0.12.0

# Safe tensor serialization required by OmniAvatar
safetensors>=0.4.0

# Image I/O library required by OmniAvatar
imageio>=2.31.0

# Scientific computing libraries required by OmniAvatar
scipy>=1.14.0

# Parameter Efficient Fine-Tuning (PEFT) for OmniAvatar
peft>=0.15.1

# Hugging Face transformers for text encoding
transformers>=4.52.3

# XFuser library specific to OmniAvatar
xfuser>=0.4.1

# Text processing utilities
ftfy

# Einstein operations for deep learning
einops

# YAML parsing for config files
PyYAML

# HuggingFace Hub for model downloading
huggingface-hub>=0.20.0

# Fast HuggingFace downloads
hf_transfer>=0.1.0

# Optional acceleration and optimization (commented out due to build issues)
# flash_attn>=2.0.0

# Build dependencies
packaging>=23.0

# Model loading and distributed inference
accelerate>=0.20.0

# Quantization support
bitsandbytes>=0.41.0

# Text tokenization
tokenizers>=0.15.0

# Configuration and serialization
protobuf>=4.0.0
regex>=2023.0.0
